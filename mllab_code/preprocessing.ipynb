{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import albumentations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "print(f'Using TensorFlow {tf.__version__}')\n",
    "\n",
    "class CFG:\n",
    "\n",
    "    root = '../input/plant-pathology-2021-fgvc8/train_images'\n",
    "    classes = [\n",
    "        'complex', \n",
    "        'frog_eye_leaf_spot', \n",
    "        'powdery_mildew', \n",
    "        'rust', \n",
    "        'scab',\n",
    "        'healthy']\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    batch_size = 64\n",
    "    \n",
    "    img_size = 512 \n",
    "    folds = 5 \n",
    "    seed = 42 \n",
    "    subfolds = 16 \n",
    "    transform = True \n",
    "    epochs = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 중복값 제거하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/plant-pathology-2021-fgvc8/train.csv', index_col='image')\n",
    "init_len = len(df)\n",
    "\n",
    "with open('../input/pp2021-duplicates-revealing/duplicates.csv', 'r') as file:\n",
    "    duplicates = [x.strip().split(',') for x in file.readlines()]\n",
    "\n",
    "for row in duplicates:\n",
    "    unique_labels = df.loc[row].drop_duplicates().values\n",
    "    if len(unique_labels) == 1:\n",
    "        df = df.drop(row[1:], axis=0)\n",
    "    else:\n",
    "        df = df.drop(row, axis=0)\n",
    "        \n",
    "print(f'Dropping {init_len - len(df)} duplicate samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels = df['labels'].values.copy()\n",
    "\n",
    "df['labels'] = [x.split(' ') for x in df['labels']]\n",
    "labels = MultiLabelBinarizer(classes=CFG.classes).fit_transform(df['labels'].values)\n",
    "\n",
    "df = pd.DataFrame(columns=CFG.classes, data=labels, index=df.index)\n",
    "\n",
    "df.to_csv('train.csv')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.stratified folds 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=CFG.folds, shuffle=True, random_state=CFG.seed)\n",
    "fold = np.zeros((len(df),))\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(df.index, original_labels)):\n",
    "    fold[val_index] = i\n",
    "\n",
    "value_counts = lambda x: pd.Series.value_counts(x, normalize=True)\n",
    "\n",
    "df_occurence = pd.DataFrame({\n",
    "    'origin': df.apply(value_counts).loc[1],\n",
    "    'fold_0': df[fold == 0].apply(value_counts).loc[1],\n",
    "    'fold_1': df[fold == 1].apply(value_counts).loc[1],\n",
    "    'fold_2': df[fold == 2].apply(value_counts).loc[1],\n",
    "    'fold_3': df[fold == 3].apply(value_counts).loc[1],\n",
    "    'fold_4': df[fold == 4].apply(value_counts).loc[1]})\n",
    "\n",
    "bar = df_occurence.plot.barh(figsize=[15, 5], colormap='plasma')\n",
    "\n",
    "folds = pd.DataFrame({\n",
    "    'image': df.index,\n",
    "    'fold': fold})\n",
    "\n",
    "folds.to_csv('folds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.transform:\n",
    "    transform = albumentations.Compose([\n",
    "       albumentations.RandomResizedCrop(CFG.img_size, CFG.img_size, scale=(0.9, 1), p=1), \n",
    "       albumentations.HorizontalFlip(p=0.5),\n",
    "       albumentations.VerticalFlip(p=0.5),\n",
    "       albumentations.ShiftScaleRotate(p=0.5),\n",
    "       albumentations.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.7),\n",
    "       albumentations.RandomBrightnessContrast(brightness_limit=(-0.2,0.2), contrast_limit=(-0.2, 0.2), p=0.7),\n",
    "       albumentations.CLAHE(clip_limit=(1,4), p=0.5),\n",
    "       albumentations.OneOf([\n",
    "           albumentations.OpticalDistortion(distort_limit=1.0),\n",
    "           albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "           albumentations.ElasticTransform(alpha=3),\n",
    "       ], p=0.2),\n",
    "       albumentations.OneOf([\n",
    "           albumentations.GaussNoise(var_limit=[10, 50]),\n",
    "           albumentations.GaussianBlur(),\n",
    "           albumentations.MotionBlur(),\n",
    "           albumentations.MedianBlur(),\n",
    "       ], p=0.2),\n",
    "      albumentations.Resize(CFG.img_size, CFG.img_size),\n",
    "      albumentations.OneOf([\n",
    "          albumentations.JpegCompression(),\n",
    "          albumentations.Downscale(scale_min=0.1, scale_max=0.15),\n",
    "      ], p=0.2),\n",
    "      albumentations.IAAPiecewiseAffine(p=0.2),\n",
    "      albumentations.IAASharpen(p=0.2),\n",
    "      albumentations.Cutout(max_h_size=int(CFG.img_size * 0.1), max_w_size=int(CFG.img_size * 0.1), num_holes=5, p=0.5),\n",
    "    ])\n",
    "else:\n",
    "    transform = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(5, 5, figsize=[15, 15])\n",
    "axes = axes.reshape(-1,)\n",
    "\n",
    "if transform is None:\n",
    "    for i in range(len(axes)):\n",
    "        image = tf.io.read_file(os.path.join(CFG.root, df.index[i]))\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [CFG.img_size, CFG.img_size])\n",
    "        image = tf.cast(image, tf.uint8)\n",
    "        \n",
    "        axes[i].imshow(image.numpy())\n",
    "        axes[i].axis('off')\n",
    "\n",
    "else:\n",
    "    image = tf.io.read_file(os.path.join(CFG.root, df.index[CFG.seed]))\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [CFG.img_size, CFG.img_size])\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "\n",
    "    for i in range(len(axes)):\n",
    "        axes[i].imshow(transform(image=image.numpy())['image'])\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.TFRecords 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def _serialize_image(path, transform=None):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [CFG.img_size, CFG.img_size])\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    \n",
    "    if transform is not None:\n",
    "        image = transform(image=image.numpy())['image']\n",
    "        \n",
    "    return tf.image.encode_jpeg(image).numpy()\n",
    "\n",
    "\n",
    "def _serialize_sample(image, image_name, label):\n",
    "    feature = {\n",
    "        'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n",
    "        'image_name': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_name])),\n",
    "        'complex': tf.train.Feature(int64_list=tf.train.Int64List(value=[label[0]])),\n",
    "        'frog_eye_leaf_spot': tf.train.Feature(int64_list=tf.train.Int64List(value=[label[1]])),\n",
    "        'powdery_mildew': tf.train.Feature(int64_list=tf.train.Int64List(value=[label[2]])),\n",
    "        'rust': tf.train.Feature(int64_list=tf.train.Int64List(value=[label[3]])),\n",
    "        'scab': tf.train.Feature(int64_list=tf.train.Int64List(value=[label[4]])),\n",
    "        'healthy': tf.train.Feature(int64_list=tf.train.Int64List(value=[label[5]]))}\n",
    "    sample = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return sample.SerializeToString()\n",
    "\n",
    "\n",
    "def serialize_fold(fold, name, transform=None, bar=None):\n",
    "    samples = []\n",
    "    \n",
    "    for image_name, labels in fold.iterrows():\n",
    "        path = os.path.join(CFG.root, image_name)\n",
    "        image = _serialize_image(path, transform=transform)\n",
    "        samples.append(_serialize_sample(image, image_name.encode(), labels))\n",
    "    \n",
    "    with tf.io.TFRecordWriter(name + '.tfrec') as writer:\n",
    "        [writer.write(x) for x in samples]\n",
    "        \n",
    "    if bar is not None:\n",
    "        bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = CFG.folds * CFG.subfolds if transform is None else CFG.folds * CFG.subfolds * CFG.epochs\n",
    "\n",
    "with tqdm(total=total) as bar:\n",
    "\n",
    "    for i in range(CFG.folds):\n",
    "\n",
    "        df_fold = df[fold == i]\n",
    "        \n",
    "        folder = f'fold_{i}'\n",
    "        \n",
    "        try:\n",
    "            os.mkdir(folder)\n",
    "        except FileExistsError:\n",
    "            shutil.rmtree(folder)\n",
    "            os.mkdir(folder)\n",
    "        \n",
    "        if transform is None:\n",
    "            for k, subfold in enumerate(np.array_split(df_fold, CFG.subfolds)):\n",
    "                name=os.path.join(folder, '%.2i-%.3i' % (k, len(subfold)))\n",
    "                serialize_fold(subfold, name=name, bar=bar)\n",
    "        else:\n",
    "            for j in range(CFG.epochs):\n",
    "                for k, subfold in enumerate(np.array_split(df_fold, CFG.subfolds)):\n",
    "                    name=os.path.join(folder, '%.2i-%.3i' % (j * CFG.subfolds + k, len(subfold)))\n",
    "                    serialize_fold(subfold, name=name, transform=transform, bar=bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test 파일 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "feature_map = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_name': tf.io.FixedLenFeature([], tf.string),\n",
    "    'complex': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'frog_eye_leaf_spot': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'powdery_mildew': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'rust': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'scab': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'healthy': tf.io.FixedLenFeature([], tf.int64)}\n",
    "\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    return np.sum([int(x[:-6].split('-')[-1]) for x in filenames])\n",
    "\n",
    "\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.reshape(image, [CFG.img_size, CFG.img_size, 3])\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "    return image\n",
    "\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    example = tf.io.parse_single_example(example, feature_map)\n",
    "    image = decode_image(example['image'])\n",
    "    target = [\n",
    "        tf.cast(example['complex'], tf.float32),\n",
    "        tf.cast(example['frog_eye_leaf_spot'], tf.float32),\n",
    "        tf.cast(example['healthy'], tf.float32),\n",
    "        tf.cast(example['powdery_mildew'], tf.float32),\n",
    "        tf.cast(example['rust'], tf.float32),\n",
    "        tf.cast(example['scab'], tf.float32)]\n",
    "    return image, target\n",
    "\n",
    "\n",
    "def get_dataset(filenames):\n",
    "    auto = tf.data.experimental.AUTOTUNE\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=auto)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=auto)\n",
    "    dataset = dataset.batch(CFG.batch_size)\n",
    "    dataset = dataset.prefetch(auto)\n",
    "    return CFG.strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.applications.EfficientNetB0(\n",
    "            include_top=False,\n",
    "            input_shape=(CFG.img_size, CFG.img_size, 3),\n",
    "            weights=None,\n",
    "            pooling='avg'),\n",
    "        tf.keras.layers.Dense(len(feature_map) - 2),\n",
    "        tf.keras.layers.Activation('sigmoid', dtype='float32')\n",
    "    ], name='EfficientNetB0')\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = tf.io.gfile.glob('./fold_0/*.tfrec')[:1]\n",
    "dataset = get_dataset(filenames)\n",
    "\n",
    "steps_per_epoch = count_data_items(filenames) // CFG.batch_size\n",
    "\n",
    "with CFG.strategy.scope():\n",
    "    model = get_model()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    dataset, \n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=1,\n",
    "    verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
